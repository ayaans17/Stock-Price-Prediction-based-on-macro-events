{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# This is a sample Jupyter Notebook\n",
    "\n",
    "Below is an example of a code cell.\n",
    "Put your cursor into the cell and press Shift+Enter to execute it and select the next one, or click 'Run Cell' button.\n",
    "\n",
    "Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "\n",
    "To learn more about Jupyter Notebooks in PyCharm, see [help](https://www.jetbrains.com/help/pycharm/ipython-notebook-support.html).\n",
    "For an overview of PyCharm, go to Help -> Learn IDE features or refer to [our documentation](https://www.jetbrains.com/help/pycharm/getting-started.html)."
   ],
   "id": "e8bb96baa0271815"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T13:30:20.615583Z",
     "start_time": "2025-10-02T13:29:08.814648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from datetime import timedelta\n",
    "\n",
    "# ------------------ Helpers ------------------\n",
    "\n",
    "def flatten_df(df):\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns = ['_'.join([str(c) for c in col if c]).strip() for col in df.columns.values]\n",
    "    df.reset_index(inplace=True)\n",
    "    return df\n",
    "\n",
    "def fetch_stock_data(ticker, years=15):\n",
    "    df = yf.download(ticker, period=f\"{years}y\")\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(columns=[\"date\", \"open\", \"high\", \"low\", \"close\", \"adj_close\", \"volume\"])\n",
    "    df = flatten_df(df)\n",
    "    df.rename(columns={\n",
    "        \"Date\": \"date\", \"Open\": \"open\", \"High\": \"high\",\n",
    "        \"Low\": \"low\", \"Close\": \"close\", \"Adj Close\": \"adj_close\",\n",
    "        \"Volume\": \"volume\"\n",
    "    }, inplace=True)\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "    #print(df.head())\n",
    "    return df\n",
    "\n",
    "def fetch_benchmark(ticker, col_name, years=15):\n",
    "    df = yf.download(ticker, period=f\"{years}y\")[[\"Close\"]]\n",
    "   # print(df.head(),col_name)\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(columns=[\"date\", col_name])\n",
    "    df = flatten_df(df)\n",
    "    df.rename(columns={\"Date\": \"date\", \"Close_\"+ticker: col_name}, inplace=True)\n",
    "    #print(df.head())\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "\n",
    "    return df[[\"date\", col_name]]\n",
    "\n",
    "def fetch_benchmarks(years=15):\n",
    "    spx = fetch_benchmark(\"^GSPC\", \"spx_close\", years)\n",
    "    ndx = fetch_benchmark(\"^NDX\", \"ndx_close\", years)\n",
    "    vix = fetch_benchmark(\"^VIX\", \"vix_close\", years)\n",
    "    return spx, ndx, vix\n",
    "\n",
    "def fetch_10y_yield(years=15):\n",
    "    df = yf.download(\"^TNX\", period=f\"{years}y\")\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(columns=[\"date\", \"dgs10_yield\"])\n",
    "    df = flatten_df(df)\n",
    "\n",
    "    df.rename(columns={\"Date\": \"date\", \"Close_^TNX\": \"dgs10_yield\"}, inplace=True)\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "    df[\"dgs10_yield\"] = df[\"dgs10_yield\"] / 10.0\n",
    "    return df[[\"date\", \"dgs10_yield\"]]\n",
    "\n",
    "def build_feature_frame(stock_df, spx_df, ndx_df, vix_df, yield_df, macro_path=None):\n",
    "    df = stock_df.copy()\n",
    "    df = df.merge(spx_df, on=\"date\", how=\"left\")\n",
    "    df = df.merge(ndx_df, on=\"date\", how=\"left\")\n",
    "    df = df.merge(vix_df, on=\"date\", how=\"left\")\n",
    "    df = df.merge(yield_df, on=\"date\", how=\"left\")\n",
    "    if macro_path:\n",
    "        macro = pd.read_csv(macro_path)\n",
    "        macro['date'] = pd.to_datetime(macro['date']).dt.date\n",
    "        macro.drop_duplicates(subset=['date'], inplace=True)\n",
    "        df = df.merge(macro, on=\"date\", how=\"left\")\n",
    "    df.fillna(method=\"ffill\", inplace=True)\n",
    "    return df\n",
    "\n",
    "# ------------------ Fetch Data ------------------\n",
    "\n",
    "stock_df = fetch_stock_data(\"QQQ\", years=15)\n",
    "spx_df, ndx_df, vix_df = fetch_benchmarks(years=15)\n",
    "yield_df = fetch_10y_yield(years=15)\n",
    "\n",
    "df = build_feature_frame(stock_df, spx_df, ndx_df, vix_df, yield_df, macro_path=None)\n",
    "df = df.sort_values(\"date\")\n",
    "\n",
    "# ------------------ Train/Test Split ------------------\n",
    "df.rename(columns={\"Open_QQQ\": \"Open\", \"High_QQQ\": \"High\",\"Volume_QQQ\":\"Volume\",\"Close_QQQ\":\"close\",\"Low_QQQ\":\"low\"}, inplace=True)\n",
    "print(df.tail())\n",
    "split_date = df['date'].iloc[0].replace(year=df['date'].iloc[0].year + 10)\n",
    "train_df = df[df['date'] < split_date]\n",
    "test_df = df[df['date'] >= split_date]\n",
    "\n",
    "feature_cols = [\"Open\", \"High\", \"Volume\", \"spx_close\", \"ndx_close\", \"vix_close\", \"dgs10_yield\"]\n",
    "\n",
    "# Close price model\n",
    "model_close = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "model_close.fit(train_df[feature_cols], train_df[\"close\"])\n",
    "pred_close = model_close.predict(test_df[feature_cols])\n",
    "\n",
    "# Low price model\n",
    "model_low = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "model_low.fit(train_df[feature_cols], train_df[\"low\"])\n",
    "pred_low = model_low.predict(test_df[feature_cols])\n",
    "\n",
    "# ------------------ Backtest Results ------------------\n",
    "\n",
    "mae_close = mean_absolute_error(test_df[\"close\"], pred_close)\n",
    "r2_close = r2_score(test_df[\"close\"], pred_close)\n",
    "mae_low = mean_absolute_error(test_df[\"low\"], pred_low)\n",
    "r2_low = r2_score(test_df[\"low\"], pred_low)\n",
    "\n",
    "print(f\"Close Price Prediction - MAE: {mae_close:.2f}, R²: {r2_close:.4f}\")\n",
    "print(f\"Low Price Prediction   - MAE: {mae_low:.2f}, R²: {r2_low:.4f}\")\n",
    "\n",
    "# ------------------ Train Full Model for Tomorrow ------------------\n",
    "\n",
    "model_close.fit(df[feature_cols], df[\"close\"])\n",
    "model_low.fit(df[feature_cols], df[\"low\"])\n",
    "\n",
    "last_row = df.iloc[-1][feature_cols].values.reshape(1, -1)\n",
    "pred_tomorrow_close = model_close.predict(last_row)[0]\n",
    "pred_tomorrow_low = model_low.predict(last_row)[0]\n",
    "\n",
    "tomorrow_date = pd.to_datetime(df['date'].iloc[-1]) + timedelta(days=1)\n",
    "\n",
    "print(\"\\n---- Tomorrow's Forecast ----\")\n",
    "print(f\"Date: {tomorrow_date.date()}\")\n",
    "print(f\"Predicted Close: {pred_tomorrow_close:.2f}\")\n",
    "print(f\"Predicted Low:   {pred_tomorrow_low:.2f}\")\n"
   ],
   "id": "11947da1890afce",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17aya\\AppData\\Local\\Temp\\ipykernel_23684\\3069387511.py:17: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, period=f\"{years}y\")\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\17aya\\AppData\\Local\\Temp\\ipykernel_23684\\3069387511.py:31: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, period=f\"{years}y\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  Close_QQQ   High_QQQ    Low_QQQ   Open_QQQ  Volume_QQQ\n",
      "0  2010-10-04  42.493675  42.993291  42.248251  42.835517    71359900\n",
      "1  2010-10-05  43.527950  43.615601  42.949448  42.975742    99301300\n",
      "2  2010-10-06  43.151073  43.571803  42.870587  43.475385    81831200\n",
      "3  2010-10-07  43.308838  43.422786  42.949465  43.396489    75693300\n",
      "4  2010-10-08  43.606850  43.712031  43.019583  43.326364    83223900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  Close_^GSPC   High_^GSPC    Low_^GSPC   Open_^GSPC  \\\n",
      "0  2010-10-04  1137.030029  1148.160034  1131.869995  1144.959961   \n",
      "1  2010-10-05  1160.750000  1162.760010  1140.680054  1140.680054   \n",
      "2  2010-10-06  1159.969971  1162.329956  1154.849976  1159.810059   \n",
      "3  2010-10-07  1158.060059  1163.869995  1151.410034  1161.569946   \n",
      "4  2010-10-08  1165.150024  1167.729980  1155.579956  1158.359985   \n",
      "\n",
      "   Volume_^GSPC  \n",
      "0    3604110000  \n",
      "1    4068840000  \n",
      "2    4073160000  \n",
      "3    3910550000  \n",
      "4    3871420000  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['spx_close'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 73\u001B[39m\n\u001B[32m     70\u001B[39m \u001B[38;5;66;03m# ------------------ Fetch Data ------------------\u001B[39;00m\n\u001B[32m     72\u001B[39m stock_df = fetch_stock_data(\u001B[33m\"\u001B[39m\u001B[33mQQQ\u001B[39m\u001B[33m\"\u001B[39m, years=\u001B[32m15\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m73\u001B[39m spx_df, ndx_df, vix_df = \u001B[43mfetch_benchmarks\u001B[49m\u001B[43m(\u001B[49m\u001B[43myears\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m15\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     74\u001B[39m yield_df = fetch_10y_yield(years=\u001B[32m15\u001B[39m)\n\u001B[32m     76\u001B[39m df = build_feature_frame(stock_df, spx_df, ndx_df, vix_df, yield_df, macro_path=\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 41\u001B[39m, in \u001B[36mfetch_benchmarks\u001B[39m\u001B[34m(years)\u001B[39m\n\u001B[32m     40\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mfetch_benchmarks\u001B[39m(years=\u001B[32m15\u001B[39m):\n\u001B[32m---> \u001B[39m\u001B[32m41\u001B[39m     spx = \u001B[43mfetch_benchmark\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m^GSPC\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mspx_close\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43myears\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     42\u001B[39m     ndx = fetch_benchmark(\u001B[33m\"\u001B[39m\u001B[33m^NDX\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mndx_close\u001B[39m\u001B[33m\"\u001B[39m, years)\n\u001B[32m     43\u001B[39m     vix = fetch_benchmark(\u001B[33m\"\u001B[39m\u001B[33m^VIX\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mvix_close\u001B[39m\u001B[33m\"\u001B[39m, years)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 38\u001B[39m, in \u001B[36mfetch_benchmark\u001B[39m\u001B[34m(ticker, col_name, years)\u001B[39m\n\u001B[32m     36\u001B[39m df[\u001B[33m'\u001B[39m\u001B[33mdate\u001B[39m\u001B[33m'\u001B[39m] = pd.to_datetime(df[\u001B[33m'\u001B[39m\u001B[33mdate\u001B[39m\u001B[33m'\u001B[39m]).dt.date\n\u001B[32m     37\u001B[39m \u001B[38;5;28mprint\u001B[39m(df.head())\n\u001B[32m---> \u001B[39m\u001B[32m38\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mdate\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcol_name\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001B[39m, in \u001B[36mDataFrame.__getitem__\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   4111\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m is_iterator(key):\n\u001B[32m   4112\u001B[39m         key = \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[32m-> \u001B[39m\u001B[32m4113\u001B[39m     indexer = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_get_indexer_strict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcolumns\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[32m1\u001B[39m]\n\u001B[32m   4115\u001B[39m \u001B[38;5;66;03m# take() does not accept boolean indexers\u001B[39;00m\n\u001B[32m   4116\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(indexer, \u001B[33m\"\u001B[39m\u001B[33mdtype\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) == \u001B[38;5;28mbool\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001B[39m, in \u001B[36mIndex._get_indexer_strict\u001B[39m\u001B[34m(self, key, axis_name)\u001B[39m\n\u001B[32m   6209\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   6210\u001B[39m     keyarr, indexer, new_indexer = \u001B[38;5;28mself\u001B[39m._reindex_non_unique(keyarr)\n\u001B[32m-> \u001B[39m\u001B[32m6212\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_raise_if_missing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeyarr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   6214\u001B[39m keyarr = \u001B[38;5;28mself\u001B[39m.take(indexer)\n\u001B[32m   6215\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Index):\n\u001B[32m   6216\u001B[39m     \u001B[38;5;66;03m# GH 42790 - Preserve name from an Index\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6264\u001B[39m, in \u001B[36mIndex._raise_if_missing\u001B[39m\u001B[34m(self, key, indexer, axis_name)\u001B[39m\n\u001B[32m   6261\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mNone of [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m] are in the [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maxis_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m]\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m   6263\u001B[39m not_found = \u001B[38;5;28mlist\u001B[39m(ensure_index(key)[missing_mask.nonzero()[\u001B[32m0\u001B[39m]].unique())\n\u001B[32m-> \u001B[39m\u001B[32m6264\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnot_found\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m not in index\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mKeyError\u001B[39m: \"['spx_close'] not in index\""
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
